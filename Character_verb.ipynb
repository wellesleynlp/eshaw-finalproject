{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"/usr/bin/java\")\n",
    "print sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import nltk\n",
    "import re, string\n",
    "\n",
    "list_of_characters=[]\n",
    "charact_vocab = collections.defaultdict(list)\n",
    "tagged_vocab = collections.defaultdict(list)\n",
    "charact_sents = collections.defaultdict(list)\n",
    "charact_verbs = collections.defaultdict(list)\n",
    "verbsets = collections.defaultdict(list)\n",
    "\n",
    "for subdir, dirs, files in os.walk('/home/eshaw/Documents/NLP/eshaw2-finalproject/txt'):\n",
    "    print len(files)\n",
    "    for file in files:\n",
    "        character_name = file[0:-4]\n",
    "        list_of_characters.append(character_name)\n",
    "        file_path = subdir + os.path.sep + file\n",
    "        shakes = open(file_path, 'r')\n",
    "        corpus = shakes.read()\n",
    "        charact_vocab[character_name] = corpus.split(\" \")\n",
    "        tagged_vocab[character_name] = nltk.pos_tag(corpus.split(\" \"))\n",
    "        charact_sents[character_name] = re.split('[?!;.:]',corpus)\n",
    "        del charact_sents[character_name][-1]\n",
    "        \n",
    "        verbs = []\n",
    "        for pair in tagged_vocab[character_name]:\n",
    "            word, tag = pair\n",
    "            if re.search('V', tag):\n",
    "                verbs.append(word)\n",
    "        charact_verbs[character_name] = verbs\n",
    "        verbsets[character_name] = set(verbs)\n",
    "# print charact_vocab['BOTTOM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jsonrpc\n",
    "from simplejson import loads\n",
    "server = jsonrpc.ServerProxy(jsonrpc.JsonRpc20(),jsonrpc.TransportTcpIp(addr=(\"127.0.0.1\", 8080)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king claudius (hamlet)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n"
     ]
    }
   ],
   "source": [
    "verb_types = collections.defaultdict(list)\n",
    "agent_tags = set(['nsubj','agent'])\n",
    "patient_tags = set(['dobj','nsubjpass','iobj'])\n",
    "# tags = set()\n",
    "\n",
    "char_dep = np.zeros((len(list_of_characters),2))\n",
    "# char_dep = collections.defaultdict(list)\n",
    "for c,character in enumerate(list_of_characters):\n",
    "    print character\n",
    "#     ag_verbs = 0\n",
    "#     pat_verbs = 0\n",
    "    cur_verbset = verbsets[character]\n",
    "    for s, sentence in enumerate(charact_sents[character]):\n",
    "        print s\n",
    "        if len(sentence)== 0 :\n",
    "            continue\n",
    "        elif sentence[0] in set(string.punctuation):\n",
    "#             print sentence\n",
    "            sentence = sentence[2:]\n",
    "        elif ' - ' in sentence:\n",
    "            sentence = sentence.replace(' - ','')\n",
    "        \n",
    "        try:\n",
    "            result = loads(server.parse(sentence))\n",
    "        except:\n",
    "            print character, s, sentence\n",
    "        for relation in result['sentences'][0]['dependencies']:\n",
    "            if (relation[1] in cur_verbset) or (relation[2] in cur_verbset):\n",
    "                if relation[0] in agent_tags:\n",
    "                    char_dep[c,0] += 1\n",
    "                elif (relation[0] in patient_tags) or ('prep_' in relation[0]):\n",
    "                    char_dep[c,1] += 1\n",
    "    #             tags.update([relation[0]])\n",
    "#     verb_types[character] = {'Agent':ag_verbs,'Patient':pat_verbs}\n",
    "\n",
    "# verb_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(charact_sents['king claudius (hamlet)'][170])\n",
    "# ans = charact_sents['lady percy'][10][1:]\n",
    "# ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RPCInternalError",
     "evalue": "<RPCFault -32603: 'Internal error.' (None)>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRPCInternalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-3aff612682ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"he's in for a commodity of brown paper and old ginger ninescore and seventeen pounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/eshaw/Documents/NLP/eshaw2-finalproject/jsonrpc.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__req\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%s.%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__req\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[1;31m#=========================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/eshaw/Documents/NLP/eshaw2-finalproject/jsonrpc.pyc\u001b[0m in \u001b[0;36m__req\u001b[1;34m(self, methodname, args, kwargs, id)\u001b[0m\n\u001b[0;32m    905\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRPCTransportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 907\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data_serializer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads_response\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mresp_str\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    908\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/eshaw/Documents/NLP/eshaw2-finalproject/jsonrpc.pyc\u001b[0m in \u001b[0;36mloads_response\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    624\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRPCInvalidMethodParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"error\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"code\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mINTERNAL_ERROR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRPCInternalError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"error\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"code\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPROCEDURE_EXCEPTION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRPCProcedureException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRPCInternalError\u001b[0m: <RPCFault -32603: 'Internal error.' (None)>"
     ]
    }
   ],
   "source": [
    "loads(server.parse(\"he's in for a commodity of brown paper and old ginger ninescore and seventeen pounds\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('/home/eshaw/Documents/NLP/eshaw2-finalproject/dream_verb_types.txt', char_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saved_verb_types = verb_types\n",
    "\n",
    "with open('/home/eshaw/Documents/NLP/eshaw2-finalproject/dream_verb_types.csv', 'wb') as f:\n",
    "    w = csv.DictWriter(f, saved_verb_types.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(saved_verb_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_verb_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "for s, sentences in enumerate(charact_sents['OBERON']):\n",
    "#     print len(sentences)\n",
    "    print s\n",
    "    ag_verbs = 0\n",
    "    pat_verbs = 0\n",
    "#     cur_verbset = verbsets[character]\n",
    "    result = loads(server.parse(sentences))\n",
    "#     print charact_sents[character][0]\n",
    "# print charact_sents['OBERON'][86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'coref': [[[[u'his', 0, 6, 46, 47],\n",
       "    [u\"I with the morning ' s\", 0, 0, 0, 6]]]],\n",
       " u'sentences': [{u'dependencies': [[u'root', u'ROOT', u'turns'],\n",
       "    [u'nsubj', u'love', u'I'],\n",
       "    [u'det', u'morning', u'the'],\n",
       "    [u'poss', u's', u'morning'],\n",
       "    [u'prep_with', u'I', u's'],\n",
       "    [u'ccomp', u'turns', u'love'],\n",
       "    [u'ccomp', u'love', u'have'],\n",
       "    [u'dobj', u'have', u'oft'],\n",
       "    [u'rcmod', u'oft', u'made'],\n",
       "    [u'dobj', u'made', u'sport'],\n",
       "    [u'det', u'forester', u'a'],\n",
       "    [u'prep_like', u'tread', u'forester'],\n",
       "    [u'det', u'groves', u'the'],\n",
       "    [u'nsubj', u'tread', u'groves'],\n",
       "    [u'aux', u'tread', u'may'],\n",
       "    [u'conj_and', u'love', u'tread'],\n",
       "    [u'advmod', u'tread', u'even'],\n",
       "    [u'det', u'gate', u'the'],\n",
       "    [u'amod', u'gate', u'eastern'],\n",
       "    [u'prep_till', u'tread', u'gate'],\n",
       "    [u'dep', u'fiery', u'all'],\n",
       "    [u'acomp', u'tread', u'fiery'],\n",
       "    [u'dep', u'fiery', u'red'],\n",
       "    [u'xcomp', u'tread', u'opening'],\n",
       "    [u'prep_on', u'opening', u'neptune'],\n",
       "    [u'dep', u'blessed', u'fair'],\n",
       "    [u'amod', u'beams', u'blessed'],\n",
       "    [u'prep_with', u'opening', u'beams'],\n",
       "    [u'amod', u'gold', u'yellow'],\n",
       "    [u'prep_into', u'turns', u'gold'],\n",
       "    [u'poss', u'salt', u'his'],\n",
       "    [u'nsubj', u'turns', u'salt'],\n",
       "    [u'amod', u'streams', u'green'],\n",
       "    [u'dep', u'salt', u'streams']],\n",
       "   u'parsetree': u\"(ROOT (SINV (S (S (NP (NP (PRP I)) (PP (IN with) (NP (NP (DT the) (NN morning) (POS ')) (NNS s)))) (VP (VBP love) (SBAR (S (VP (VBP have) (NP (NP (NN oft)) (SBAR (S (VP (VBD made) (NP (NN sport))))))))))) (, ,) (CC and) (S (, ,) (PP (IN like) (NP (DT a) (NN forester))) (, ,) (NP (DT the) (NNS groves)) (VP (MD may) (VP (VB tread) (, ,) (ADVP (RB even)) (PP (IN till) (NP (DT the) (JJ eastern) (NN gate))) (, ,) (ADJP (DT all) (ADJP (JJ fiery)) (: -) (ADJP (JJ red))) (, ,) (S (VP (VBG opening) (PP (IN on) (NP (NN neptune))) (PP (IN with) (NP (ADJP (JJ fair) (VBN blessed)) (NNS beams))))))))) (, ,) (VP (VBZ turns) (PP (IN into) (NP (JJ yellow) (NN gold)))) (NP (NP (PRP$ his) (NN salt)) (NP (JJ green) (NNS streams)))))\",\n",
       "   u'text': u\"I with the morning ' s love have oft made sport , and , like a forester , the groves may tread , even till the eastern gate , all fiery - red , opening on neptune with fair blessed beams , turns into yellow gold his salt green streams\",\n",
       "   u'words': [[u'I',\n",
       "     {u'CharacterOffsetBegin': u'0',\n",
       "      u'CharacterOffsetEnd': u'1',\n",
       "      u'Lemma': u'I',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'PRP'}],\n",
       "    [u'with',\n",
       "     {u'CharacterOffsetBegin': u'2',\n",
       "      u'CharacterOffsetEnd': u'6',\n",
       "      u'Lemma': u'with',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'IN'}],\n",
       "    [u'the',\n",
       "     {u'CharacterOffsetBegin': u'7',\n",
       "      u'CharacterOffsetEnd': u'10',\n",
       "      u'Lemma': u'the',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'DT'}],\n",
       "    [u'morning',\n",
       "     {u'CharacterOffsetBegin': u'11',\n",
       "      u'CharacterOffsetEnd': u'18',\n",
       "      u'Lemma': u'morning',\n",
       "      u'NamedEntityTag': u'TIME',\n",
       "      u'NormalizedNamedEntityTag': u'TMO',\n",
       "      u'PartOfSpeech': u'NN',\n",
       "      u'Timex': u'<TIMEX3 tid=\"t1\" type=\"TIME\" value=\"TMO\">morning</TIMEX3>'}],\n",
       "    [u\"'\",\n",
       "     {u'CharacterOffsetBegin': u'19',\n",
       "      u'CharacterOffsetEnd': u'20',\n",
       "      u'Lemma': u\"'\",\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'POS'}],\n",
       "    [u's',\n",
       "     {u'CharacterOffsetBegin': u'21',\n",
       "      u'CharacterOffsetEnd': u'22',\n",
       "      u'Lemma': u's',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'NNS'}],\n",
       "    [u'love',\n",
       "     {u'CharacterOffsetBegin': u'23',\n",
       "      u'CharacterOffsetEnd': u'27',\n",
       "      u'Lemma': u'love',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'VBP'}],\n",
       "    [u'have',\n",
       "     {u'CharacterOffsetBegin': u'28',\n",
       "      u'CharacterOffsetEnd': u'32',\n",
       "      u'Lemma': u'have',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'VBP'}],\n",
       "    [u'oft',\n",
       "     {u'CharacterOffsetBegin': u'33',\n",
       "      u'CharacterOffsetEnd': u'36',\n",
       "      u'Lemma': u'oft',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'NN'}],\n",
       "    [u'made',\n",
       "     {u'CharacterOffsetBegin': u'37',\n",
       "      u'CharacterOffsetEnd': u'41',\n",
       "      u'Lemma': u'make',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'VBD'}],\n",
       "    [u'sport',\n",
       "     {u'CharacterOffsetBegin': u'42',\n",
       "      u'CharacterOffsetEnd': u'47',\n",
       "      u'Lemma': u'sport',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'NN'}],\n",
       "    [u',',\n",
       "     {u'CharacterOffsetBegin': u'48',\n",
       "      u'CharacterOffsetEnd': u'49',\n",
       "      u'Lemma': u',',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u','}],\n",
       "    [u'and',\n",
       "     {u'CharacterOffsetBegin': u'50',\n",
       "      u'CharacterOffsetEnd': u'53',\n",
       "      u'Lemma': u'and',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'CC'}],\n",
       "    [u',',\n",
       "     {u'CharacterOffsetBegin': u'54',\n",
       "      u'CharacterOffsetEnd': u'55',\n",
       "      u'Lemma': u',',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u','}],\n",
       "    [u'like',\n",
       "     {u'CharacterOffsetBegin': u'56',\n",
       "      u'CharacterOffsetEnd': u'60',\n",
       "      u'Lemma': u'like',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'IN'}],\n",
       "    [u'a',\n",
       "     {u'CharacterOffsetBegin': u'61',\n",
       "      u'CharacterOffsetEnd': u'62',\n",
       "      u'Lemma': u'a',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'DT'}],\n",
       "    [u'forester',\n",
       "     {u'CharacterOffsetBegin': u'63',\n",
       "      u'CharacterOffsetEnd': u'71',\n",
       "      u'Lemma': u'forester',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'NN'}],\n",
       "    [u',',\n",
       "     {u'CharacterOffsetBegin': u'72',\n",
       "      u'CharacterOffsetEnd': u'73',\n",
       "      u'Lemma': u',',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u','}],\n",
       "    [u'the',\n",
       "     {u'CharacterOffsetBegin': u'74',\n",
       "      u'CharacterOffsetEnd': u'77',\n",
       "      u'Lemma': u'the',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'DT'}],\n",
       "    [u'groves',\n",
       "     {u'CharacterOffsetBegin': u'78',\n",
       "      u'CharacterOffsetEnd': u'84',\n",
       "      u'Lemma': u'grove',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'NNS'}],\n",
       "    [u'may',\n",
       "     {u'CharacterOffsetBegin': u'85',\n",
       "      u'CharacterOffsetEnd': u'88',\n",
       "      u'Lemma': u'may',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'MD'}],\n",
       "    [u'tread',\n",
       "     {u'CharacterOffsetBegin': u'89',\n",
       "      u'CharacterOffsetEnd': u'94',\n",
       "      u'Lemma': u'tread',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'VB'}],\n",
       "    [u',',\n",
       "     {u'CharacterOffsetBegin': u'95',\n",
       "      u'CharacterOffsetEnd': u'96',\n",
       "      u'Lemma': u',',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u','}],\n",
       "    [u'even',\n",
       "     {u'CharacterOffsetBegin': u'97',\n",
       "      u'CharacterOffsetEnd': u'101',\n",
       "      u'Lemma': u'even',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'RB'}],\n",
       "    [u'till',\n",
       "     {u'CharacterOffsetBegin': u'102',\n",
       "      u'CharacterOffsetEnd': u'106',\n",
       "      u'Lemma': u'till',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'IN'}],\n",
       "    [u'the',\n",
       "     {u'CharacterOffsetBegin': u'107',\n",
       "      u'CharacterOffsetEnd': u'110',\n",
       "      u'Lemma': u'the',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'DT'}],\n",
       "    [u'eastern',\n",
       "     {u'CharacterOffsetBegin': u'111',\n",
       "      u'CharacterOffsetEnd': u'118',\n",
       "      u'Lemma': u'eastern',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'JJ'}],\n",
       "    [u'gate',\n",
       "     {u'CharacterOffsetBegin': u'119',\n",
       "      u'CharacterOffsetEnd': u'123',\n",
       "      u'Lemma': u'gate',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'NN'}],\n",
       "    [u',',\n",
       "     {u'CharacterOffsetBegin': u'124',\n",
       "      u'CharacterOffsetEnd': u'125',\n",
       "      u'Lemma': u',',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u','}],\n",
       "    [u'all',\n",
       "     {u'CharacterOffsetBegin': u'126',\n",
       "      u'CharacterOffsetEnd': u'129',\n",
       "      u'Lemma': u'all',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'DT'}],\n",
       "    [u'fiery',\n",
       "     {u'CharacterOffsetBegin': u'130',\n",
       "      u'CharacterOffsetEnd': u'135',\n",
       "      u'Lemma': u'fiery',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'JJ'}],\n",
       "    [u'-',\n",
       "     {u'CharacterOffsetBegin': u'136',\n",
       "      u'CharacterOffsetEnd': u'137',\n",
       "      u'Lemma': u'-',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u':'}],\n",
       "    [u'red',\n",
       "     {u'CharacterOffsetBegin': u'138',\n",
       "      u'CharacterOffsetEnd': u'141',\n",
       "      u'Lemma': u'red',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'JJ'}],\n",
       "    [u',',\n",
       "     {u'CharacterOffsetBegin': u'142',\n",
       "      u'CharacterOffsetEnd': u'143',\n",
       "      u'Lemma': u',',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u','}],\n",
       "    [u'opening',\n",
       "     {u'CharacterOffsetBegin': u'144',\n",
       "      u'CharacterOffsetEnd': u'151',\n",
       "      u'Lemma': u'open',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'VBG'}],\n",
       "    [u'on',\n",
       "     {u'CharacterOffsetBegin': u'152',\n",
       "      u'CharacterOffsetEnd': u'154',\n",
       "      u'Lemma': u'on',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'IN'}],\n",
       "    [u'neptune',\n",
       "     {u'CharacterOffsetBegin': u'155',\n",
       "      u'CharacterOffsetEnd': u'162',\n",
       "      u'Lemma': u'neptune',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'NN'}],\n",
       "    [u'with',\n",
       "     {u'CharacterOffsetBegin': u'163',\n",
       "      u'CharacterOffsetEnd': u'167',\n",
       "      u'Lemma': u'with',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'IN'}],\n",
       "    [u'fair',\n",
       "     {u'CharacterOffsetBegin': u'168',\n",
       "      u'CharacterOffsetEnd': u'172',\n",
       "      u'Lemma': u'fair',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'JJ'}],\n",
       "    [u'blessed',\n",
       "     {u'CharacterOffsetBegin': u'173',\n",
       "      u'CharacterOffsetEnd': u'180',\n",
       "      u'Lemma': u'bless',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'VBN'}],\n",
       "    [u'beams',\n",
       "     {u'CharacterOffsetBegin': u'181',\n",
       "      u'CharacterOffsetEnd': u'186',\n",
       "      u'Lemma': u'beam',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'NNS'}],\n",
       "    [u',',\n",
       "     {u'CharacterOffsetBegin': u'187',\n",
       "      u'CharacterOffsetEnd': u'188',\n",
       "      u'Lemma': u',',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u','}],\n",
       "    [u'turns',\n",
       "     {u'CharacterOffsetBegin': u'189',\n",
       "      u'CharacterOffsetEnd': u'194',\n",
       "      u'Lemma': u'turn',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'VBZ'}],\n",
       "    [u'into',\n",
       "     {u'CharacterOffsetBegin': u'195',\n",
       "      u'CharacterOffsetEnd': u'199',\n",
       "      u'Lemma': u'into',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'IN'}],\n",
       "    [u'yellow',\n",
       "     {u'CharacterOffsetBegin': u'200',\n",
       "      u'CharacterOffsetEnd': u'206',\n",
       "      u'Lemma': u'yellow',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'JJ'}],\n",
       "    [u'gold',\n",
       "     {u'CharacterOffsetBegin': u'207',\n",
       "      u'CharacterOffsetEnd': u'211',\n",
       "      u'Lemma': u'gold',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'NN'}],\n",
       "    [u'his',\n",
       "     {u'CharacterOffsetBegin': u'212',\n",
       "      u'CharacterOffsetEnd': u'215',\n",
       "      u'Lemma': u'he',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'PRP$'}],\n",
       "    [u'salt',\n",
       "     {u'CharacterOffsetBegin': u'216',\n",
       "      u'CharacterOffsetEnd': u'220',\n",
       "      u'Lemma': u'salt',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'NN'}],\n",
       "    [u'green',\n",
       "     {u'CharacterOffsetBegin': u'221',\n",
       "      u'CharacterOffsetEnd': u'226',\n",
       "      u'Lemma': u'green',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'JJ'}],\n",
       "    [u'streams',\n",
       "     {u'CharacterOffsetBegin': u'227',\n",
       "      u'CharacterOffsetEnd': u'234',\n",
       "      u'Lemma': u'stream',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'NNS'}]]}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loads(server.parse(\"I with the morning ' s love have oft made sport , and , like a forester , the groves may tread , even till the eastern gate , all fiery - red , opening on neptune with fair blessed beams , turns into yellow gold his salt green streams\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "nsubj\n",
      "advmod\n",
      "aux\n",
      "xcomp\n",
      "dobj\n",
      "advmod\n",
      "dobj\n",
      "prep_by\n",
      "prepc_according_to\n",
      "det\n",
      "pobj\n"
     ]
    }
   ],
   "source": [
    "result = loads(server.parse(charact_sents['BOTTOM'][0]))\n",
    "for relation in result['sentences'][0]['dependencies']:\n",
    "    print relation[0]\n",
    "#     if relation[1] or relation[2] in cur_verbset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'scrip' in verbsets['BOTTOM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "Could not find stanford-parser\\.jar jar file at /home/eshaw/Documents/NLP/eshaw2-finalproject/stanford-parser-full-2015-12-09/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-b9ca37dc7aa4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpath_to_jar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/home/eshaw/Documents/NLP/eshaw2-finalproject/stanford-parser-full-2015-12-09/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpath_to_models_jar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/home/eshaw/Documents/NLP/eshaw2-finalproject/stanford-parser-full-2015-12-09/stanford-parser-3.4.1-models.jar'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdependency_parser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStanfordDependencyParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_jar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_to_jar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_to_models_jar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_to_models_jar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdependency_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'I shot an elephant in my sleep'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/eshaw/anaconda2/lib/python2.7/site-packages/nltk/parse/stanford.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_to_jar, path_to_models_jar, model_path, encoding, verbose, java_options, corenlp_options)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_regex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             ),\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_JAR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         )\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/eshaw/anaconda2/lib/python2.7/site-packages/nltk/__init__.pyc\u001b[0m in \u001b[0;36mfind_jar_iter\u001b[1;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m             raise LookupError('Could not find %s jar file at %s' %\n\u001b[1;32m--> 568\u001b[1;33m                             (name_pattern, path_to_jar))\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;31m# Check environment variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: Could not find stanford-parser\\.jar jar file at /home/eshaw/Documents/NLP/eshaw2-finalproject/stanford-parser-full-2015-12-09/"
     ]
    }
   ],
   "source": [
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "\n",
    "path_to_jar = '/home/eshaw/Documents/NLP/eshaw2-finalproject/stanford-parser-full-2015-12-09/'\n",
    "path_to_models_jar = '/home/eshaw/Documents/NLP/eshaw2-finalproject/stanford-parser-full-2015-12-09/stanford-parser-3.4.1-models.jar'\n",
    "dependency_parser = StanfordDependencyParser(path_to_jar=path_to_jar, path_to_models_jar=path_to_models_jar)\n",
    "\n",
    "result = dependency_parser.raw_parse('I shot an elephant in my sleep')\n",
    "dep = result.next()\n",
    "list(dep.triples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of tab-delimited fields (1) not supported by CoNLL(10) or Malt-Tab(4) format",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d430be4a8cb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdependencygraph\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDependencyGraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mDependencyGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# DependencyGraph(\"Pick up the tire pallet.\", top_relation_label='root')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# dependencies = self.parser.parseToStanfordDependencies(\"Pick up the tire pallet.\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/eshaw/anaconda2/lib/python2.7/site-packages/nltk/parse/dependencygraph.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, tree_str, cell_extractor, zero_based, cell_separator, top_relation_label)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[0mzero_based\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzero_based\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[0mcell_separator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcell_separator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                 \u001b[0mtop_relation_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_relation_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m             )\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/eshaw/anaconda2/lib/python2.7/site-packages/nltk/parse/dependencygraph.pyc\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(self, input_, cell_extractor, zero_based, cell_separator, top_relation_label)\u001b[0m\n\u001b[0;32m    334\u001b[0m                     raise ValueError(\n\u001b[0;32m    335\u001b[0m                         \u001b[1;34m'Number of tab-delimited fields ({0}) not supported by '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m                         \u001b[1;34m'CoNLL(10) or Malt-Tab(4) format'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m                     )\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of tab-delimited fields (1) not supported by CoNLL(10) or Malt-Tab(4) format"
     ]
    }
   ],
   "source": [
    "from nltk.parse.dependencygraph import DependencyGraph\n",
    "\n",
    "DependencyGraph(result)\n",
    "# DependencyGraph(\"Pick up the tire pallet.\", top_relation_label='root')\n",
    "# dependencies = self.parser.parseToStanfordDependencies(\"Pick up the tire pallet.\")\n",
    "# tupleResult = [(rel, gov.text, dep.text) for rel, gov, dep in dependencies.dependencies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
